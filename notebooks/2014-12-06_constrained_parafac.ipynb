{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parafac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 17:04:09,885] A new study created in memory with name: test_study\n",
      "[I 2024-12-06 17:04:09,888] Trial 0 finished with value: 1.7142857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'ab', 'x_1_0': 'ab', 'x_1_1': 'ab'}. Best is trial 0 with value: 1.7142857142857144.\n",
      "[I 2024-12-06 17:04:09,967] Trial 1 finished with value: 1.5714285714285714 and parameters: {'x_0_0': 'bc', 'x_0_1': 'bd', 'x_1_0': 'cd', 'x_1_1': 'ac'}. Best is trial 0 with value: 1.7142857142857144.\n",
      "[I 2024-12-06 17:04:10,049] Trial 2 finished with value: 1.875 and parameters: {'x_0_0': 'oo', 'x_0_1': 'cd', 'x_1_0': 'ad', 'x_1_1': 'ac'}. Best is trial 2 with value: 1.875.\n",
      "[I 2024-12-06 17:04:10,131] Trial 3 finished with value: 1.875 and parameters: {'x_0_0': 'oo', 'x_0_1': 'ad', 'x_1_0': 'ab', 'x_1_1': 'ac'}. Best is trial 2 with value: 1.875.\n",
      "[I 2024-12-06 17:04:10,216] Trial 4 finished with value: 2.0 and parameters: {'x_0_0': 'cd', 'x_0_1': 'bd', 'x_1_0': 'bc', 'x_1_1': 'bd'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,310] Trial 5 finished with value: 0.9285714285714286 and parameters: {'x_0_0': 'ad', 'x_0_1': 'oo', 'x_1_0': 'ab', 'x_1_1': 'ac'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,403] Trial 6 finished with value: 1.5714285714285714 and parameters: {'x_0_0': 'bc', 'x_0_1': 'cd', 'x_1_0': 'ac', 'x_1_1': 'cd'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,491] Trial 7 finished with value: 1.4285714285714286 and parameters: {'x_0_0': 'ac', 'x_0_1': 'ab', 'x_1_0': 'ad', 'x_1_1': 'ad'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,579] Trial 8 finished with value: 1.4642857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'ad', 'x_1_0': 'oo', 'x_1_1': 'bc'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,656] Trial 9 finished with value: 1.2142857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'oo', 'x_1_0': 'bd', 'x_1_1': 'ad'}. Best is trial 4 with value: 2.0.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import optuna\n",
    "from functools import partial\n",
    "from _src import ParafacSampler_v1, WarcraftObjective\n",
    "\n",
    "def objective(trial, map_shape=None, objective_function=None):\n",
    "    directions = [\"oo\", \"ab\", \"ac\", \"ad\", \"bc\", \"bd\", \"cd\"]\n",
    "    x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            x[i, j] = trial.suggest_categorical(f\"x_{i}_{j}\", directions)\n",
    "    return objective_function(x)\n",
    "\n",
    "def get_map(map_option: int):\n",
    "    if map_option == 1:\n",
    "        map_targeted = np.array([[1, 4], [2, 1]])\n",
    "    elif map_option == 2:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 1]])\n",
    "    elif map_option == 3:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 3], [5, 2, 1]])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid map option: {map_option}\")\n",
    "    return map_targeted / map_targeted.sum()\n",
    "\n",
    "def run_bo():\n",
    "    settings = {\n",
    "        \"name\": \"test_study\",\n",
    "        \"seed\": 0,\n",
    "        \"map_option\": 1,\n",
    "        \"iter_bo\": 10,\n",
    "        \"unique_sampling\": False,\n",
    "        \"decomp_num\": 5,\n",
    "        \"cp_settings\": {\n",
    "            \"rank\": 2,\n",
    "            \"als_iterations\": 100,\n",
    "            \"mask_ratio\": 0.1,\n",
    "            \"include_observed_points\": False,\n",
    "        },\n",
    "        \"acqf_settings\": {\n",
    "            \"acquisition_function\": \"ucb\",\n",
    "            \"trade_off_param\": 3.0,\n",
    "            \"batch_size\": 10,\n",
    "            \"maximize\": True,\n",
    "        },\n",
    "        \"n_startup_trials\": 10,\n",
    "    }\n",
    "\n",
    "    random.seed(settings['seed'])\n",
    "\n",
    "    map_targeted = get_map(settings[\"map_option\"])\n",
    "    map_shape = map_targeted.shape\n",
    "    objective_function = WarcraftObjective(map_targeted)\n",
    "    objective_with_args = partial(objective, map_shape=map_shape, objective_function=objective_function)\n",
    "\n",
    "    sampler = ParafacSampler_v1(\n",
    "        cp_rank=settings[\"cp_settings\"][\"rank\"],\n",
    "        als_iter_num=settings[\"cp_settings\"][\"als_iterations\"],\n",
    "        mask_ratio=settings[\"cp_settings\"][\"mask_ratio\"],\n",
    "        acquisition_function=settings[\"acqf_settings\"][\"acquisition_function\"],\n",
    "        trade_off_param=settings[\"acqf_settings\"][\"trade_off_param\"],\n",
    "        seed=settings[\"seed\"],\n",
    "        unique_sampling=settings[\"unique_sampling\"],\n",
    "        decomp_iter_num=settings[\"decomp_num\"],\n",
    "        include_observed_points=settings[\"cp_settings\"].get(\"include_observed_points\", False),\n",
    "    )\n",
    "\n",
    "    direction = \"maximize\" if settings[\"acqf_settings\"][\"maximize\"] else \"minimize\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=settings[\"name\"],\n",
    "        sampler=sampler,\n",
    "        direction=direction,\n",
    "    )\n",
    "\n",
    "    study.optimize(objective_with_args, n_trials=settings[\"iter_bo\"])\n",
    "\n",
    "    best_x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            best_x[i, j] = study.best_params[f\"x_{i}_{j}\"]\n",
    "\n",
    "    optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_bo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained Parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_constraint_warcraft() -> np.ndarray:\n",
    "    # Directions dictionary\n",
    "    directions_dict = {\n",
    "        \"oo\": np.array([0, 0]),\n",
    "        \"ab\": np.array([1, 1]),\n",
    "        \"ac\": np.array([0, 2]),\n",
    "        \"ad\": np.array([1, 1]),\n",
    "        \"bc\": np.array([1, 1]),\n",
    "        \"bd\": np.array([2, 0]),\n",
    "        \"cd\": np.array([1, 1]),\n",
    "    }\n",
    "\n",
    "    directions_list = list(directions_dict.keys())\n",
    "\n",
    "    # Map parameters\n",
    "    map_shape = (2, 3)\n",
    "    map_length = map_shape[0] * map_shape[1]\n",
    "    ideal_gain = (map_shape[0] + map_shape[1] - 1) * 2\n",
    "\n",
    "    # Initialize constraints as NumPy arrays\n",
    "    tensor_constraint_1 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_2 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_3 = np.zeros((len(directions_list),) * map_length)\n",
    "\n",
    "    # Constraint 1: (0, 0) != \"oo\", \"ab\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"ab\"]:\n",
    "            tensor_constraint_1[..., directions_list.index(direction)] = 1\n",
    "\n",
    "    # Constraint 2: (map_shape[0] - 1, map_shape[1] - 1) != \"oo\", \"cd\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"cd\"]:\n",
    "            tensor_constraint_2[directions_list.index(direction), ...] = 1\n",
    "\n",
    "    # Constraint 3: len[path] == map_shape[0] * map_shape[1]\n",
    "    for index, _ in np.ndenumerate(tensor_constraint_3):\n",
    "        gain = np.sum([directions_dict[directions_list[idx]].sum() for idx in index])\n",
    "        if gain == ideal_gain:\n",
    "            tensor_constraint_3[index] = 1\n",
    "\n",
    "    # Combine constraints with logical AND\n",
    "    tensor_constraint = np.logical_and(\n",
    "        tensor_constraint_1,\n",
    "        np.logical_and(tensor_constraint_2, tensor_constraint_3)\n",
    "    )\n",
    "\n",
    "    return tensor_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import BaseSampler\n",
    "from optuna.trial import TrialState\n",
    "from scipy.stats import norm\n",
    "from tensorly import cp_to_tensor\n",
    "from tensorly.decomposition import parafac\n",
    "\n",
    "\n",
    "class ParafacSampler(BaseSampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seed: Optional[int] = None,\n",
    "        cp_rank: int = 3,\n",
    "        als_iter_num: int = 10,\n",
    "        mask_ratio: float = 0.2,\n",
    "        trade_off_param: float = 1.0,\n",
    "        unique_sampling: bool = False,\n",
    "        decomp_iter_num: int = 5,\n",
    "        include_observed_points: bool = False,\n",
    "        acquisition_function: Literal[\"ucb\", \"ei\"] = \"ucb\",  # 追加: 獲得関数の選択\n",
    "        n_startup_trials: int = 1,\n",
    "        independent_sampler: Literal[\"random\"] = \"random\",  # Remove qmc option\n",
    "        tensor_constraint = None,\n",
    "    ):\n",
    "        # Random seed\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        random.seed(seed)  # Ensure the global random seed is set\n",
    "\n",
    "        # Initialization\n",
    "        self.cp_rank = cp_rank\n",
    "        self.als_iter_num = als_iter_num\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.trade_off_param = trade_off_param\n",
    "        self.unique_sampling = unique_sampling\n",
    "        self.decomp_iter_num = decomp_iter_num\n",
    "        self.include_observed_points = include_observed_points\n",
    "        self.acquisition_function = acquisition_function  # 追加: 獲得関数の設定\n",
    "        self.n_startup_trials = n_startup_trials\n",
    "        self.independent_sampler = independent_sampler  # Store the independent sampler choice\n",
    "\n",
    "        # Internal storage\n",
    "        self._param_names = None\n",
    "        self._category_maps = None\n",
    "        self._shape = None\n",
    "        self._evaluated_indices = []\n",
    "        self._tensor_eval = None\n",
    "        self._tensor_eval_bool = None\n",
    "        self._tensor_constraint = tensor_constraint\n",
    "        self._maximize = None\n",
    "\n",
    "        # Debugging\n",
    "        self.mean_tensor = None\n",
    "        self.std_tensor = None\n",
    "        self.save_dir = None\n",
    "\n",
    "    def infer_relative_search_space(self, study, trial):\n",
    "        search_space = optuna.search_space.intersection_search_space(\n",
    "            study.get_trials(deepcopy=False)\n",
    "        )\n",
    "        relevant_search_space = {}\n",
    "        for name, distribution in search_space.items():\n",
    "            if isinstance(\n",
    "                distribution,\n",
    "                (\n",
    "                    optuna.distributions.IntDistribution,\n",
    "                    optuna.distributions.CategoricalDistribution,\n",
    "                ),\n",
    "            ):\n",
    "                relevant_search_space[name] = distribution\n",
    "        return relevant_search_space\n",
    "\n",
    "    def sample_relative(self, study, trial, search_space):\n",
    "        if not search_space:\n",
    "            return {}\n",
    "        \n",
    "        states = (TrialState.COMPLETE,)\n",
    "        trials = study._get_trials(deepcopy=False, states=states, use_cache=True)\n",
    "        \n",
    "        if len(trials) < self.n_startup_trials:  # Corrected attribute name\n",
    "            return {}\n",
    "\n",
    "        if self._param_names is None:\n",
    "            self._initialize_internal_structure(search_space, study)\n",
    "\n",
    "        # Build tensor from past trials\n",
    "        self._update_tensor(study)\n",
    "\n",
    "        # Perform CP decomposition and suggest next parameter set\n",
    "        mean_tensor, std_tensor = self._fit(\n",
    "            self._tensor_eval,\n",
    "            self._tensor_eval_bool,\n",
    "        )\n",
    "\n",
    "        # Suggest next indices based on the selected acquisition function\n",
    "        if self.acquisition_function == \"ucb\":\n",
    "            next_indices = self._suggest_ucb_candidates(\n",
    "                mean_tensor=mean_tensor,\n",
    "                std_tensor=std_tensor,\n",
    "                trade_off_param=self.trade_off_param,\n",
    "                batch_size=1,\n",
    "                maximize=self._maximize,\n",
    "            )\n",
    "        elif self.acquisition_function == \"ei\":\n",
    "            next_indices = self._suggest_ei_candidates(\n",
    "                mean_tensor=mean_tensor,\n",
    "                std_tensor=std_tensor,\n",
    "                batch_size=1,\n",
    "                maximize=self._maximize,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"acquisition_function must be either 'ucb' or 'ei'.\")\n",
    "\n",
    "        next_index = next_indices[0]\n",
    "\n",
    "        # Convert indices back to parameter values\n",
    "        params = {}\n",
    "        for i, param_name in enumerate(self._param_names):\n",
    "            category_index = next_index[i]\n",
    "            category = self._category_maps[param_name][category_index]\n",
    "            params[param_name] = category\n",
    "\n",
    "        return params\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        logging.info(f\"Using sample_independent for sampling with {self.independent_sampler} sampler.\")\n",
    "        if self.independent_sampler == \"random\":\n",
    "            sampler = optuna.samplers.RandomSampler(seed=self.seed)  # Pass the seed to the sampler\n",
    "        else:\n",
    "            raise ValueError(\"independent_sampler must be 'random'.\")\n",
    "        return sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "    def _initialize_internal_structure(self, search_space, study):\n",
    "        self._param_names = sorted(search_space.keys())\n",
    "        self._category_maps = {}\n",
    "        self._shape = []\n",
    "        for param_name in self._param_names:\n",
    "            distribution = search_space[param_name]\n",
    "            if isinstance(distribution, optuna.distributions.CategoricalDistribution):\n",
    "                categories = distribution.choices\n",
    "            elif isinstance(distribution, optuna.distributions.IntDistribution):\n",
    "                categories = list(\n",
    "                    range(distribution.low, distribution.high + 1, distribution.step)\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "            self._category_maps[param_name] = categories\n",
    "            self._shape.append(len(categories))\n",
    "        self._shape = tuple(self._shape)\n",
    "        self._tensor_eval = np.full(self._shape, np.nan)\n",
    "        self._tensor_eval_bool = np.zeros(self._shape, dtype=bool)\n",
    "        self._evaluated_indices = []\n",
    "        self._maximize = study.direction == optuna.study.StudyDirection.MAXIMIZE\n",
    "\n",
    "    def _update_tensor(self, study):\n",
    "        trials = study.get_trials(deepcopy=False)\n",
    "        for trial in trials:\n",
    "            if trial.state != optuna.trial.TrialState.COMPLETE:\n",
    "                continue\n",
    "            index = []\n",
    "            for param_name in self._param_names:\n",
    "                if param_name not in trial.params:\n",
    "                    break\n",
    "                category = trial.params[param_name]\n",
    "                try:\n",
    "                    category_index = self._category_maps[param_name].index(category)\n",
    "                except ValueError:\n",
    "                    break\n",
    "                index.append(category_index)\n",
    "            else:\n",
    "                index = tuple(index)\n",
    "                if index not in self._evaluated_indices:\n",
    "                    value = trial.value\n",
    "                    self._tensor_eval[index] = value\n",
    "                    self._tensor_eval_bool[index] = True\n",
    "                    self._evaluated_indices.append(index)\n",
    "\n",
    "        # Debugging (optional saving)\n",
    "        trial_num = trial.number - 1\n",
    "        if trial_num >= 1:\n",
    "            self._save_tensor(self._tensor_eval, \"tensor_eval\", trial_num)\n",
    "            self._save_tensor(self._tensor_eval_bool, \"tensor_eval_bool\", trial_num)\n",
    "            self._save_tensor(self.mean_tensor, \"mean_tensor\", trial_num)\n",
    "            self._save_tensor(self.std_tensor, \"std_tensor\", trial_num)\n",
    "\n",
    "    def _save_tensor(self, tensor: np.ndarray, name: str, trial_index: int):\n",
    "        import os\n",
    "        if self.save_dir:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "            filepath = os.path.join(self.save_dir, f\"{name}_trial{trial_index}.npy\")\n",
    "            np.save(filepath, tensor)\n",
    "            print(f\"Saved {name} for trial {trial_index} at {filepath}\")\n",
    "\n",
    "    def _fit(\n",
    "        self,\n",
    "        tensor_eval: np.ndarray,\n",
    "        tensor_eval_bool: np.ndarray,\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        eval_mean, eval_std = self._calculate_eval_stats(\n",
    "            tensor_eval\n",
    "        )\n",
    "\n",
    "        tensors_list = [\n",
    "            self._decompose_with_optional_mask(\n",
    "                tensor_eval,\n",
    "                tensor_eval_bool,\n",
    "                eval_mean,\n",
    "                eval_std,\n",
    "            )\n",
    "            for _ in range(self.decomp_iter_num)\n",
    "        ]\n",
    "\n",
    "        return self._calculate_mean_std_tensors(\n",
    "            tensors_list, tensor_eval, tensor_eval_bool\n",
    "        )\n",
    "\n",
    "    def _calculate_eval_stats(\n",
    "        self, tensor_eval: np.ndarray\n",
    "    ) -> tuple[float, float, float, float]:\n",
    "        finite_values = tensor_eval[np.isfinite(tensor_eval)]\n",
    "        return (\n",
    "            np.nanmean(finite_values),\n",
    "            np.nanstd(finite_values),\n",
    "        )\n",
    "\n",
    "    def _select_mask_indices(\n",
    "        self, tensor_shape: tuple, tensor_eval_bool: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        cand_indices = (\n",
    "            np.indices(tensor_shape).reshape(len(tensor_shape), -1).T\n",
    "            if self.include_observed_points\n",
    "            else np.argwhere(tensor_eval_bool == False)\n",
    "        )\n",
    "        mask_size = max(1, int(len(cand_indices) * self.mask_ratio))\n",
    "        # return self.rng.choice(cand_indices, mask_size, replace=False)  # Use self.rng.choice instead of random.sample\n",
    "        return random.sample(list(cand_indices), mask_size)\n",
    "\n",
    "    def _create_mask_tensor(\n",
    "        self, tensor_shape: tuple, mask_indices: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        mask_tensor = np.ones(tensor_shape, dtype=bool)\n",
    "        for mask_index in mask_indices:\n",
    "            mask_tensor[tuple(mask_index)] = False\n",
    "        return mask_tensor\n",
    "\n",
    "    def _decompose_with_optional_mask(\n",
    "        self,\n",
    "        tensor_eval: np.ndarray,\n",
    "        tensor_eval_bool: np.ndarray,\n",
    "        eval_mean: float,\n",
    "        eval_std: float,\n",
    "    ) -> np.ndarray:\n",
    "        # Standardize tensor_eval\n",
    "        standardized_tensor_eval = (tensor_eval - eval_mean) / (eval_std + 1e-8)\n",
    "        standardized_tensor_eval[~tensor_eval_bool] = np.nan  # Set unobserved points to NaN\n",
    "\n",
    "        # Create mask if needed\n",
    "        mask_tensor = None\n",
    "        if self.mask_ratio != 0:\n",
    "            mask_indices = self._select_mask_indices(\n",
    "                tensor_eval.shape, tensor_eval_bool\n",
    "            )\n",
    "            mask_tensor = self._create_mask_tensor(tensor_eval.shape, mask_indices)\n",
    "\n",
    "        init_tensor_eval = self.rng.normal(0, 1, tensor_eval.shape)\n",
    "\n",
    "\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        ######################################################################\n",
    "        \n",
    "        # # Apply constraints\n",
    "        # if self._tensor_constraint:\n",
    "        #     init_tensor_eval = np.where(\n",
    "        #         self._tensor_constraint == 0, \n",
    "        #         -100 if self._maximize else 100, \n",
    "        #         init_tensor_eval\n",
    "        #     )\n",
    "\n",
    "        # Assign observed values\n",
    "        init_tensor_eval[tensor_eval_bool] = standardized_tensor_eval[tensor_eval_bool]\n",
    "\n",
    "        # Perform CP decomposition\n",
    "        cp_tensor = parafac(\n",
    "            init_tensor_eval,\n",
    "            rank=self.cp_rank,\n",
    "            mask=mask_tensor,\n",
    "            n_iter_max=self.als_iter_num,\n",
    "            init=\"random\",\n",
    "            random_state=self.rng,  # Ensure the random state is passed\n",
    "        )\n",
    "        return cp_to_tensor(cp_tensor)\n",
    "\n",
    "    def _calculate_mean_std_tensors(\n",
    "        self,\n",
    "        tensors_list: list[np.ndarray],\n",
    "        tensor_eval: np.ndarray,\n",
    "        tensor_eval_bool: np.ndarray,\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        tensors_stack = np.stack(tensors_list)\n",
    "        mean_tensor = np.mean(tensors_stack, axis=0)\n",
    "        std_tensor = np.std(tensors_stack, axis=0)\n",
    "        mean_tensor[tensor_eval_bool] = tensor_eval[tensor_eval_bool]\n",
    "        std_tensor[tensor_eval_bool] = 0\n",
    "\n",
    "        # Debugging\n",
    "        self.mean_tensor = mean_tensor\n",
    "        self.std_tensor = std_tensor\n",
    "\n",
    "        return mean_tensor, std_tensor\n",
    "\n",
    "    def _suggest_ucb_candidates(\n",
    "        self,\n",
    "        mean_tensor: np.ndarray,\n",
    "        std_tensor: np.ndarray,\n",
    "        trade_off_param: float,\n",
    "        batch_size: int,\n",
    "        maximize: bool,\n",
    "    ) -> list[tuple[int, ...]]:\n",
    "        # # Calculate overall mean and std stats for logging\n",
    "        # mean_stats = {\n",
    "        #     \"Max\": np.max(mean_tensor),\n",
    "        #     \"Min\": np.min(mean_tensor),\n",
    "        #     \"Mean\": np.mean(mean_tensor),\n",
    "        #     \"Std\": np.std(mean_tensor),\n",
    "        # }\n",
    "        # std_stats = {\n",
    "        #     \"Max\": np.max(std_tensor),\n",
    "        #     \"Min\": np.min(std_tensor),\n",
    "        #     \"Mean\": np.mean(std_tensor),\n",
    "        #     \"Std\": np.std(std_tensor),\n",
    "        # }\n",
    "\n",
    "        # logging.info(f\"Candidate Mean Stats: {mean_stats}\")\n",
    "        # logging.info(f\"Candidate Std Stats: {std_stats}\")\n",
    "\n",
    "        # Define UCB calculation\n",
    "        def _ucb(mean_tensor, std_tensor, trade_off_param, maximize=True) -> np.ndarray:\n",
    "            mean_tensor = mean_tensor if maximize else -mean_tensor\n",
    "            ucb_values = mean_tensor + trade_off_param * std_tensor\n",
    "            return ucb_values\n",
    "\n",
    "        ucb_values = _ucb(mean_tensor, std_tensor, trade_off_param, maximize)\n",
    "\n",
    "        if self.unique_sampling:\n",
    "            ucb_values[self._tensor_eval_bool == True] = -np.inf\n",
    "\n",
    "        # Get indices of top UCB values\n",
    "        flat_indices = np.argsort(ucb_values.flatten())[::-1]\n",
    "        top_indices = np.unravel_index(flat_indices[:batch_size], ucb_values.shape)\n",
    "        top_indices = list(zip(*top_indices))\n",
    "\n",
    "        return top_indices\n",
    "\n",
    "    def _suggest_ei_candidates(\n",
    "        self,\n",
    "        mean_tensor: np.ndarray,\n",
    "        std_tensor: np.ndarray,\n",
    "        batch_size: int,\n",
    "        maximize: bool,\n",
    "    ) -> list[tuple[int, ...]]:\n",
    "        # # Calculate overall mean and std stats for logging\n",
    "        # mean_stats = {\n",
    "        #     \"Max\": np.max(mean_tensor),\n",
    "        #     \"Min\": np.min(mean_tensor),\n",
    "        #     \"Mean\": np.mean(mean_tensor),\n",
    "        #     \"Std\": np.std(mean_tensor),\n",
    "        # }\n",
    "        # std_stats = {\n",
    "        #     \"Max\": np.max(std_tensor),\n",
    "        #     \"Min\": np.min(std_tensor),\n",
    "        #     \"Mean\": np.mean(std_tensor),\n",
    "        #     \"Std\": np.std(std_tensor),\n",
    "        # }\n",
    "\n",
    "        # Define EI calculation\n",
    "        def _ei(mean_tensor, std_tensor, f_best, maximize=True) -> np.ndarray:\n",
    "            std_tensor = np.clip(std_tensor, 1e-9, None)\n",
    "            if maximize:\n",
    "                z = (mean_tensor - f_best) / std_tensor\n",
    "            else:\n",
    "                z = (f_best - mean_tensor) / std_tensor\n",
    "            ei_values = std_tensor * (z * norm.cdf(z) + norm.pdf(z))\n",
    "            return ei_values\n",
    "\n",
    "        if maximize:\n",
    "            f_best = np.nanmax(self._tensor_eval)\n",
    "        else:\n",
    "            f_best = np.nanmin(self._tensor_eval)\n",
    "\n",
    "        ei_values = _ei(mean_tensor, std_tensor, f_best=f_best, maximize=maximize)\n",
    "\n",
    "        if self.unique_sampling:\n",
    "            ei_values[self._tensor_eval_bool == True] = -np.inf\n",
    "\n",
    "        # Get indices of top EI values\n",
    "        flat_indices = np.argsort(ei_values.flatten())[::-1]\n",
    "        top_indices = np.unravel_index(flat_indices[:batch_size], ei_values.shape)\n",
    "        top_indices = list(zip(*top_indices))\n",
    "\n",
    "        return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 20:50:06,055] A new study created in memory with name: test_study\n",
      "[I 2024-12-06 20:50:06,060] Trial 0 finished with value: 1.7142857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'ab', 'x_1_0': 'ab', 'x_1_1': 'ab'}. Best is trial 0 with value: 1.7142857142857144.\n",
      "[I 2024-12-06 20:50:06,147] Trial 1 finished with value: 1.5714285714285714 and parameters: {'x_0_0': 'bc', 'x_0_1': 'bd', 'x_1_0': 'cd', 'x_1_1': 'ac'}. Best is trial 0 with value: 1.7142857142857144.\n",
      "[I 2024-12-06 20:50:06,226] Trial 2 finished with value: 1.875 and parameters: {'x_0_0': 'oo', 'x_0_1': 'cd', 'x_1_0': 'ad', 'x_1_1': 'ac'}. Best is trial 2 with value: 1.875.\n",
      "[I 2024-12-06 20:50:06,307] Trial 3 finished with value: 1.875 and parameters: {'x_0_0': 'oo', 'x_0_1': 'ad', 'x_1_0': 'ab', 'x_1_1': 'ac'}. Best is trial 2 with value: 1.875.\n",
      "[I 2024-12-06 20:50:06,392] Trial 4 finished with value: 2.0 and parameters: {'x_0_0': 'cd', 'x_0_1': 'bd', 'x_1_0': 'bc', 'x_1_1': 'bd'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 20:50:06,512] Trial 5 finished with value: 0.9285714285714286 and parameters: {'x_0_0': 'ad', 'x_0_1': 'oo', 'x_1_0': 'ab', 'x_1_1': 'ac'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 20:50:06,604] Trial 6 finished with value: 1.5714285714285714 and parameters: {'x_0_0': 'bc', 'x_0_1': 'cd', 'x_1_0': 'ac', 'x_1_1': 'cd'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 20:50:06,691] Trial 7 finished with value: 1.4285714285714286 and parameters: {'x_0_0': 'ac', 'x_0_1': 'ab', 'x_1_0': 'ad', 'x_1_1': 'ad'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 20:50:06,779] Trial 8 finished with value: 1.4642857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'ad', 'x_1_0': 'oo', 'x_1_1': 'bc'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 20:50:06,854] Trial 9 finished with value: 1.2142857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'oo', 'x_1_0': 'bd', 'x_1_1': 'ad'}. Best is trial 4 with value: 2.0.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import optuna\n",
    "from functools import partial\n",
    "from _src import WarcraftObjective\n",
    "\n",
    "\n",
    "def build_constraint_warcraft(map_shape: tuple[int, int]) -> np.ndarray:\n",
    "    # Directions dictionary\n",
    "    directions_dict = {\n",
    "        \"oo\": np.array([0, 0]),\n",
    "        \"ab\": np.array([1, 1]),\n",
    "        \"ac\": np.array([0, 2]),\n",
    "        \"ad\": np.array([1, 1]),\n",
    "        \"bc\": np.array([1, 1]),\n",
    "        \"bd\": np.array([2, 0]),\n",
    "        \"cd\": np.array([1, 1]),\n",
    "    }\n",
    "\n",
    "    directions_list = list(directions_dict.keys())\n",
    "\n",
    "    # Map parameters\n",
    "    map_length = map_shape[0] * map_shape[1]\n",
    "    ideal_gain = (map_shape[0] + map_shape[1] - 1) * 2\n",
    "\n",
    "    # Initialize constraints as NumPy arrays\n",
    "    tensor_constraint_1 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_2 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_3 = np.zeros((len(directions_list),) * map_length)\n",
    "\n",
    "    # Constraint 1: (0, 0) != \"oo\", \"ab\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"ab\"]:\n",
    "            tensor_constraint_1[..., directions_list.index(direction)] = 1\n",
    "\n",
    "    # Constraint 2: (map_shape[0] - 1, map_shape[1] - 1) != \"oo\", \"cd\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"cd\"]:\n",
    "            tensor_constraint_2[directions_list.index(direction), ...] = 1\n",
    "\n",
    "    # Constraint 3: len[path] == map_shape[0] * map_shape[1]\n",
    "    for index, _ in np.ndenumerate(tensor_constraint_3):\n",
    "        gain = np.sum([directions_dict[directions_list[idx]].sum() for idx in index])\n",
    "        if gain == ideal_gain:\n",
    "            tensor_constraint_3[index] = 1\n",
    "\n",
    "    # Combine constraints with logical AND\n",
    "    tensor_constraint = np.logical_and(\n",
    "        tensor_constraint_1,\n",
    "        np.logical_and(tensor_constraint_2, tensor_constraint_3)\n",
    "    )\n",
    "\n",
    "    return tensor_constraint\n",
    "\n",
    "\n",
    "def objective(trial, map_shape=None, objective_function=None):\n",
    "    directions = [\"oo\", \"ab\", \"ac\", \"ad\", \"bc\", \"bd\", \"cd\"]\n",
    "    x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            x[i, j] = trial.suggest_categorical(f\"x_{i}_{j}\", directions)\n",
    "    return objective_function(x)\n",
    "\n",
    "\n",
    "def get_map(map_option: int):\n",
    "    if map_option == 1:\n",
    "        map_targeted = np.array([[1, 4], [2, 1]])\n",
    "    elif map_option == 2:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 1]])\n",
    "    elif map_option == 3:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 3], [5, 2, 1]])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid map option: {map_option}\")\n",
    "    return map_targeted / map_targeted.sum()\n",
    "\n",
    "\n",
    "def run_bo():\n",
    "    settings = {\n",
    "        \"name\": \"test_study\",\n",
    "        \"seed\": 0,\n",
    "        \"map_option\": 1,\n",
    "        \"iter_bo\": 10,\n",
    "        \"unique_sampling\": False,\n",
    "        \"decomp_num\": 5,\n",
    "        \"cp_settings\": {\n",
    "            \"rank\": 2,\n",
    "            \"als_iterations\": 100,\n",
    "            \"mask_ratio\": 0.1,\n",
    "            \"include_observed_points\": False,\n",
    "        },\n",
    "        \"acqf_settings\": {\n",
    "            \"acquisition_function\": \"ucb\",\n",
    "            \"trade_off_param\": 3.0,\n",
    "            \"batch_size\": 10,\n",
    "            \"maximize\": True,\n",
    "        },\n",
    "        \"n_startup_trials\": 10,\n",
    "    }\n",
    "\n",
    "    random.seed(settings['seed'])\n",
    "\n",
    "    map_targeted = get_map(settings[\"map_option\"])\n",
    "    map_shape = map_targeted.shape\n",
    "    objective_function = WarcraftObjective(map_targeted)\n",
    "    objective_with_args = partial(objective, map_shape=map_shape, objective_function=objective_function)\n",
    "\n",
    "    sampler = ParafacSampler(\n",
    "        cp_rank=settings[\"cp_settings\"][\"rank\"],\n",
    "        als_iter_num=settings[\"cp_settings\"][\"als_iterations\"],\n",
    "        mask_ratio=settings[\"cp_settings\"][\"mask_ratio\"],\n",
    "        acquisition_function=settings[\"acqf_settings\"][\"acquisition_function\"],\n",
    "        trade_off_param=settings[\"acqf_settings\"][\"trade_off_param\"],\n",
    "        seed=settings[\"seed\"],\n",
    "        unique_sampling=settings[\"unique_sampling\"],\n",
    "        decomp_iter_num=settings[\"decomp_num\"],\n",
    "        include_observed_points=settings[\"cp_settings\"].get(\"include_observed_points\", False),\n",
    "        tensor_constraint=build_constraint_warcraft(map_shape),\n",
    "    )\n",
    "\n",
    "    direction = \"maximize\" if settings[\"acqf_settings\"][\"maximize\"] else \"minimize\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=settings[\"name\"],\n",
    "        sampler=sampler,\n",
    "        direction=direction,\n",
    "    )\n",
    "\n",
    "    study.optimize(objective_with_args, n_trials=settings[\"iter_bo\"])\n",
    "\n",
    "    best_x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            best_x[i, j] = study.best_params[f\"x_{i}_{j}\"]\n",
    "\n",
    "    optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_bo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo-env_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
