{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parafac "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 17:04:09,885] A new study created in memory with name: test_study\n",
      "[I 2024-12-06 17:04:09,888] Trial 0 finished with value: 1.7142857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'ab', 'x_1_0': 'ab', 'x_1_1': 'ab'}. Best is trial 0 with value: 1.7142857142857144.\n",
      "[I 2024-12-06 17:04:09,967] Trial 1 finished with value: 1.5714285714285714 and parameters: {'x_0_0': 'bc', 'x_0_1': 'bd', 'x_1_0': 'cd', 'x_1_1': 'ac'}. Best is trial 0 with value: 1.7142857142857144.\n",
      "[I 2024-12-06 17:04:10,049] Trial 2 finished with value: 1.875 and parameters: {'x_0_0': 'oo', 'x_0_1': 'cd', 'x_1_0': 'ad', 'x_1_1': 'ac'}. Best is trial 2 with value: 1.875.\n",
      "[I 2024-12-06 17:04:10,131] Trial 3 finished with value: 1.875 and parameters: {'x_0_0': 'oo', 'x_0_1': 'ad', 'x_1_0': 'ab', 'x_1_1': 'ac'}. Best is trial 2 with value: 1.875.\n",
      "[I 2024-12-06 17:04:10,216] Trial 4 finished with value: 2.0 and parameters: {'x_0_0': 'cd', 'x_0_1': 'bd', 'x_1_0': 'bc', 'x_1_1': 'bd'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,310] Trial 5 finished with value: 0.9285714285714286 and parameters: {'x_0_0': 'ad', 'x_0_1': 'oo', 'x_1_0': 'ab', 'x_1_1': 'ac'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,403] Trial 6 finished with value: 1.5714285714285714 and parameters: {'x_0_0': 'bc', 'x_0_1': 'cd', 'x_1_0': 'ac', 'x_1_1': 'cd'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,491] Trial 7 finished with value: 1.4285714285714286 and parameters: {'x_0_0': 'ac', 'x_0_1': 'ab', 'x_1_0': 'ad', 'x_1_1': 'ad'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,579] Trial 8 finished with value: 1.4642857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'ad', 'x_1_0': 'oo', 'x_1_1': 'bc'}. Best is trial 4 with value: 2.0.\n",
      "[I 2024-12-06 17:04:10,656] Trial 9 finished with value: 1.2142857142857144 and parameters: {'x_0_0': 'ab', 'x_0_1': 'oo', 'x_1_0': 'bd', 'x_1_1': 'ad'}. Best is trial 4 with value: 2.0.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import optuna\n",
    "from functools import partial\n",
    "from _src import ParafacSampler_v1, WarcraftObjective\n",
    "\n",
    "def objective(trial, map_shape=None, objective_function=None):\n",
    "    directions = [\"oo\", \"ab\", \"ac\", \"ad\", \"bc\", \"bd\", \"cd\"]\n",
    "    x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            x[i, j] = trial.suggest_categorical(f\"x_{i}_{j}\", directions)\n",
    "    return objective_function(x)\n",
    "\n",
    "def get_map(map_option: int):\n",
    "    if map_option == 1:\n",
    "        map_targeted = np.array([[1, 4], [2, 1]])\n",
    "    elif map_option == 2:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 1]])\n",
    "    elif map_option == 3:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 3], [5, 2, 1]])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid map option: {map_option}\")\n",
    "    return map_targeted / map_targeted.sum()\n",
    "\n",
    "def run_bo():\n",
    "    settings = {\n",
    "        \"name\": \"test_study\",\n",
    "        \"seed\": 0,\n",
    "        \"map_option\": 1,\n",
    "        \"iter_bo\": 10,\n",
    "        \"unique_sampling\": False,\n",
    "        \"decomp_num\": 5,\n",
    "        \"cp_settings\": {\n",
    "            \"rank\": 2,\n",
    "            \"als_iterations\": 100,\n",
    "            \"mask_ratio\": 0.1,\n",
    "            \"include_observed_points\": False,\n",
    "        },\n",
    "        \"acqf_settings\": {\n",
    "            \"acquisition_function\": \"ucb\",\n",
    "            \"trade_off_param\": 3.0,\n",
    "            \"batch_size\": 10,\n",
    "            \"maximize\": True,\n",
    "        },\n",
    "        \"n_startup_trials\": 10,\n",
    "    }\n",
    "\n",
    "    random.seed(settings['seed'])\n",
    "\n",
    "    map_targeted = get_map(settings[\"map_option\"])\n",
    "    map_shape = map_targeted.shape\n",
    "    objective_function = WarcraftObjective(map_targeted)\n",
    "    objective_with_args = partial(objective, map_shape=map_shape, objective_function=objective_function)\n",
    "\n",
    "    sampler = ParafacSampler_v1(\n",
    "        cp_rank=settings[\"cp_settings\"][\"rank\"],\n",
    "        als_iter_num=settings[\"cp_settings\"][\"als_iterations\"],\n",
    "        mask_ratio=settings[\"cp_settings\"][\"mask_ratio\"],\n",
    "        acquisition_function=settings[\"acqf_settings\"][\"acquisition_function\"],\n",
    "        trade_off_param=settings[\"acqf_settings\"][\"trade_off_param\"],\n",
    "        seed=settings[\"seed\"],\n",
    "        unique_sampling=settings[\"unique_sampling\"],\n",
    "        decomp_iter_num=settings[\"decomp_num\"],\n",
    "        include_observed_points=settings[\"cp_settings\"].get(\"include_observed_points\", False),\n",
    "    )\n",
    "\n",
    "    direction = \"maximize\" if settings[\"acqf_settings\"][\"maximize\"] else \"minimize\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=settings[\"name\"],\n",
    "        sampler=sampler,\n",
    "        direction=direction,\n",
    "    )\n",
    "\n",
    "    study.optimize(objective_with_args, n_trials=settings[\"iter_bo\"])\n",
    "\n",
    "    best_x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            best_x[i, j] = study.best_params[f\"x_{i}_{j}\"]\n",
    "\n",
    "    optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_bo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constrained Parafac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def build_constraint_warcraft() -> np.ndarray:\n",
    "    # Directions dictionary\n",
    "    directions_dict = {\n",
    "        \"oo\": np.array([0, 0]),\n",
    "        \"ab\": np.array([1, 1]),\n",
    "        \"ac\": np.array([0, 2]),\n",
    "        \"ad\": np.array([1, 1]),\n",
    "        \"bc\": np.array([1, 1]),\n",
    "        \"bd\": np.array([2, 0]),\n",
    "        \"cd\": np.array([1, 1]),\n",
    "    }\n",
    "\n",
    "    directions_list = list(directions_dict.keys())\n",
    "\n",
    "    # Map parameters\n",
    "    map_shape = (2, 3)\n",
    "    map_length = map_shape[0] * map_shape[1]\n",
    "    ideal_gain = (map_shape[0] + map_shape[1] - 1) * 2\n",
    "\n",
    "    # Initialize constraints as NumPy arrays\n",
    "    tensor_constraint_1 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_2 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_3 = np.zeros((len(directions_list),) * map_length)\n",
    "\n",
    "    # Constraint 1: (0, 0) != \"oo\", \"ab\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"ab\"]:\n",
    "            tensor_constraint_1[..., directions_list.index(direction)] = 1\n",
    "\n",
    "    # Constraint 2: (map_shape[0] - 1, map_shape[1] - 1) != \"oo\", \"cd\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"cd\"]:\n",
    "            tensor_constraint_2[directions_list.index(direction), ...] = 1\n",
    "\n",
    "    # Constraint 3: len[path] == map_shape[0] * map_shape[1]\n",
    "    for index, _ in np.ndenumerate(tensor_constraint_3):\n",
    "        gain = np.sum([directions_dict[directions_list[idx]].sum() for idx in index])\n",
    "        if gain == ideal_gain:\n",
    "            tensor_constraint_3[index] = 1\n",
    "\n",
    "    # Combine constraints with logical AND\n",
    "    tensor_constraint = np.logical_and(\n",
    "        tensor_constraint_1,\n",
    "        np.logical_and(tensor_constraint_2, tensor_constraint_3)\n",
    "    )\n",
    "\n",
    "    return tensor_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import random\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.samplers import BaseSampler\n",
    "from optuna.trial import TrialState\n",
    "from scipy.stats import norm\n",
    "from tensorly import cp_to_tensor\n",
    "from tensorly.decomposition import parafac\n",
    "\n",
    "\n",
    "class ParafacSampler(BaseSampler):\n",
    "    def __init__(\n",
    "        self,\n",
    "        seed: Optional[int] = None,\n",
    "        cp_rank: int = 3,\n",
    "        als_iter_num: int = 10,\n",
    "        mask_ratio: float = 0.2,\n",
    "        trade_off_param: float = 1.0,\n",
    "        unique_sampling: bool = False,\n",
    "        decomp_iter_num: int = 5,\n",
    "        include_observed_points: bool = False,\n",
    "        acquisition_function: Literal[\"ucb\", \"ei\"] = \"ucb\",  # 追加: 獲得関数の選択\n",
    "        n_startup_trials: int = 1,\n",
    "        tensor_constraint = None,\n",
    "    ):\n",
    "        # Random seed\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed)\n",
    "        random.seed(seed)  # Ensure the global random seed is set\n",
    "\n",
    "        # Initialization\n",
    "        self.cp_rank = cp_rank\n",
    "        self.als_iter_num = als_iter_num\n",
    "        self.mask_ratio = mask_ratio\n",
    "        self.trade_off_param = trade_off_param\n",
    "        self.unique_sampling = unique_sampling\n",
    "        self.decomp_iter_num = decomp_iter_num\n",
    "        self.include_observed_points = include_observed_points\n",
    "        self.acquisition_function = acquisition_function  # 追加: 獲得関数の設定\n",
    "        self.n_startup_trials = n_startup_trials\n",
    "        self.independent_sampler = optuna.samplers.RandomSampler(seed=seed)\n",
    "\n",
    "        # Internal storage\n",
    "        self._param_names = None\n",
    "        self._category_maps = None\n",
    "        self._shape = None\n",
    "        self._evaluated_indices = []\n",
    "        self._tensor_eval = None\n",
    "        self._tensor_eval_bool = None\n",
    "        self._tensor_constraint = tensor_constraint\n",
    "        self._maximize = None\n",
    "\n",
    "        # Debugging\n",
    "        self.mean_tensor = None\n",
    "        self.std_tensor = None\n",
    "        self.save_dir = None\n",
    "\n",
    "    def infer_relative_search_space(self, study, trial):\n",
    "        search_space = optuna.search_space.intersection_search_space(\n",
    "            study.get_trials(deepcopy=False)\n",
    "        )\n",
    "        relevant_search_space = {}\n",
    "        for name, distribution in search_space.items():\n",
    "            if isinstance(\n",
    "                distribution,\n",
    "                (\n",
    "                    optuna.distributions.IntDistribution,\n",
    "                    optuna.distributions.CategoricalDistribution,\n",
    "                ),\n",
    "            ):\n",
    "                relevant_search_space[name] = distribution\n",
    "        return relevant_search_space\n",
    "\n",
    "    def sample_relative(self, study, trial, search_space):\n",
    "        if not search_space:\n",
    "            return {}\n",
    "        \n",
    "        states = (TrialState.COMPLETE,)\n",
    "        trials = study._get_trials(deepcopy=False, states=states, use_cache=True)\n",
    "        \n",
    "        if len(trials) < self.n_startup_trials:  # Corrected attribute name\n",
    "            return {}\n",
    "\n",
    "        if self._param_names is None:\n",
    "            self._initialize_internal_structure(search_space, study)\n",
    "\n",
    "        # Build tensor from past trials\n",
    "        self._update_tensor(study)\n",
    "\n",
    "        # Perform CP decomposition and suggest next parameter set\n",
    "        mean_tensor, std_tensor = self._fit(\n",
    "            self._tensor_eval,\n",
    "            self._tensor_eval_bool,\n",
    "        )\n",
    "\n",
    "        # Suggest next indices based on the selected acquisition function\n",
    "        if self.acquisition_function == \"ucb\":\n",
    "            next_indices = self._suggest_ucb_candidates(\n",
    "                mean_tensor=mean_tensor,\n",
    "                std_tensor=std_tensor,\n",
    "                trade_off_param=self.trade_off_param,\n",
    "                batch_size=1,\n",
    "                maximize=self._maximize,\n",
    "            )\n",
    "        elif self.acquisition_function == \"ei\":\n",
    "            next_indices = self._suggest_ei_candidates(\n",
    "                mean_tensor=mean_tensor,\n",
    "                std_tensor=std_tensor,\n",
    "                batch_size=1,\n",
    "                maximize=self._maximize,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(\"acquisition_function must be either 'ucb' or 'ei'.\")\n",
    "\n",
    "        next_index = next_indices[0]\n",
    "\n",
    "        # Convert indices back to parameter values\n",
    "        params = {}\n",
    "        for i, param_name in enumerate(self._param_names):\n",
    "            category_index = next_index[i]\n",
    "            category = self._category_maps[param_name][category_index]\n",
    "            params[param_name] = category\n",
    "\n",
    "        return params\n",
    "\n",
    "    def sample_independent(self, study, trial, param_name, param_distribution):\n",
    "        logging.info(f\"Using sample_independent for sampling with {self.independent_sampler} sampler.\")\n",
    "        return self.independent_sampler.sample_independent(study, trial, param_name, param_distribution)\n",
    "\n",
    "    def _initialize_internal_structure(self, search_space, study):\n",
    "        self._param_names = sorted(search_space.keys())\n",
    "        self._category_maps = {}\n",
    "        self._shape = []\n",
    "        for param_name in self._param_names:\n",
    "            distribution = search_space[param_name]\n",
    "            if isinstance(distribution, optuna.distributions.CategoricalDistribution):\n",
    "                categories = distribution.choices\n",
    "            elif isinstance(distribution, optuna.distributions.IntDistribution):\n",
    "                categories = list(\n",
    "                    range(distribution.low, distribution.high + 1, distribution.step)\n",
    "                )\n",
    "            else:\n",
    "                continue\n",
    "            self._category_maps[param_name] = categories\n",
    "            self._shape.append(len(categories))\n",
    "        self._shape = tuple(self._shape)\n",
    "        self._tensor_eval = np.full(self._shape, np.nan)\n",
    "        self._tensor_eval_bool = np.zeros(self._shape, dtype=bool)\n",
    "        self._evaluated_indices = []\n",
    "        self._maximize = study.direction == optuna.study.StudyDirection.MAXIMIZE\n",
    "\n",
    "    def _update_tensor(self, study):\n",
    "        trials = study.get_trials(deepcopy=False)\n",
    "        for trial in trials:\n",
    "            if trial.state != optuna.trial.TrialState.COMPLETE:\n",
    "                continue\n",
    "            index = []\n",
    "            for param_name in self._param_names:\n",
    "                if param_name not in trial.params:\n",
    "                    break\n",
    "                category = trial.params[param_name]\n",
    "                try:\n",
    "                    category_index = self._category_maps[param_name].index(category)\n",
    "                except ValueError:\n",
    "                    break\n",
    "                index.append(category_index)\n",
    "            else:\n",
    "                index = tuple(index)\n",
    "                if index not in self._evaluated_indices:\n",
    "                    value = trial.value\n",
    "                    self._tensor_eval[index] = value\n",
    "                    self._tensor_eval_bool[index] = True\n",
    "                    self._evaluated_indices.append(index)\n",
    "\n",
    "        # Debugging (optional saving)\n",
    "        trial_num = trial.number - 1\n",
    "        if trial_num >= 1:\n",
    "            self._save_tensor(self._tensor_eval, \"tensor_eval\", trial_num)\n",
    "            self._save_tensor(self._tensor_eval_bool, \"tensor_eval_bool\", trial_num)\n",
    "            self._save_tensor(self.mean_tensor, \"mean_tensor\", trial_num)\n",
    "            self._save_tensor(self.std_tensor, \"std_tensor\", trial_num)\n",
    "\n",
    "    def _save_tensor(self, tensor: np.ndarray, name: str, trial_index: int):\n",
    "        import os\n",
    "        if self.save_dir:\n",
    "            os.makedirs(self.save_dir, exist_ok=True)\n",
    "            filepath = os.path.join(self.save_dir, f\"{name}_trial{trial_index}.npy\")\n",
    "            np.save(filepath, tensor)\n",
    "            print(f\"Saved {name} for trial {trial_index} at {filepath}\")\n",
    "\n",
    "    def _fit(\n",
    "        self,\n",
    "        tensor_eval: np.ndarray,\n",
    "        tensor_eval_bool: np.ndarray,\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        eval_mean, eval_std = self._calculate_eval_stats(\n",
    "            tensor_eval\n",
    "        )\n",
    "\n",
    "        tensors_list = [\n",
    "            self._decompose_with_optional_mask(\n",
    "                tensor_eval,\n",
    "                tensor_eval_bool,\n",
    "                eval_mean,\n",
    "                eval_std,\n",
    "                self._maximize\n",
    "            )\n",
    "            for _ in range(self.decomp_iter_num)\n",
    "        ]\n",
    "\n",
    "        return self._calculate_mean_std_tensors(\n",
    "            tensors_list, tensor_eval, tensor_eval_bool, self._maximize\n",
    "        )\n",
    "\n",
    "    def _calculate_eval_stats(\n",
    "        self, tensor_eval: np.ndarray\n",
    "    ) -> tuple[float, float, float, float]:\n",
    "        eval_copy = np.copy(tensor_eval)\n",
    "        # Filter with constraint\n",
    "        eval_copy[self._tensor_constraint == 0] = np.nan\n",
    "\n",
    "        finite_values = eval_copy[np.isfinite(eval_copy)]\n",
    "\n",
    "        return (\n",
    "            np.nanmean(finite_values),\n",
    "            np.nanstd(finite_values),\n",
    "        )\n",
    "\n",
    "    # def _select_mask_indices(\n",
    "    #     self, tensor_shape: tuple, tensor_eval_bool: np.ndarray\n",
    "    # ) -> np.ndarray:\n",
    "    #     cand_indices = (\n",
    "    #         np.indices(tensor_shape).reshape(len(tensor_shape), -1).T\n",
    "    #         if self.include_observed_points\n",
    "    #         else np.argwhere(tensor_eval_bool == False)\n",
    "    #     )\n",
    "\n",
    "    #     mask_size = max(1, int(len(cand_indices) * self.mask_ratio))\n",
    "    #     # return self.rng.choice(cand_indices, mask_size, replace=False)  # Use self.rng.choice instead of random.sample\n",
    "    #     return random.sample(list(cand_indices), mask_size)\n",
    "\n",
    "    def _select_mask_indices(\n",
    "        self, tensor_shape: tuple, tensor_eval_bool: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        # Get candidate indices where self._tensor_constraint is 1\n",
    "        constrained_indices = np.argwhere(self._tensor_constraint == 1)\n",
    "\n",
    "        # Filter candidate indices based on whether to include observed points\n",
    "        if self.include_observed_points:\n",
    "            cand_indices = np.indices(tensor_shape).reshape(len(tensor_shape), -1).T\n",
    "        else:\n",
    "            cand_indices = np.argwhere(tensor_eval_bool == False)\n",
    "\n",
    "\n",
    "        # # Too slow ---------------------------------------------\n",
    "        # # Intersect the constrained indices with the candidate indices\n",
    "        # cand_indices = np.array([tuple(idx) for idx in cand_indices if tuple(idx) in map(tuple, constrained_indices)])\n",
    "        # # Too slow ---------------------------------------------\n",
    "\n",
    "        # Intersect the constrained indices with the candidate indices\n",
    "        constrained_indices_set = set(map(tuple, constrained_indices))\n",
    "        cand_indices = np.array([idx for idx in cand_indices if tuple(idx) in constrained_indices_set])\n",
    "\n",
    "        # Determine the mask size\n",
    "        mask_size = max(1, int(len(cand_indices) * self.mask_ratio))\n",
    "\n",
    "        # Select mask indices\n",
    "        selected_indices = self.rng.choice(len(cand_indices), mask_size, replace=False)\n",
    "        return cand_indices[selected_indices]\n",
    "\n",
    "    def _create_mask_tensor(\n",
    "        self, tensor_shape: tuple, mask_indices: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        mask_tensor = np.ones(tensor_shape, dtype=bool)\n",
    "        for mask_index in mask_indices:\n",
    "            mask_tensor[tuple(mask_index)] = False\n",
    "        return mask_tensor\n",
    "\n",
    "    def _decompose_with_optional_mask(\n",
    "        self,\n",
    "        tensor_eval: np.ndarray,\n",
    "        tensor_eval_bool: np.ndarray,\n",
    "        eval_mean: float,\n",
    "        eval_std: float,\n",
    "        maximize: bool\n",
    "    ) -> np.ndarray:\n",
    "        # Standardize tensor_eval\n",
    "        standardized_tensor_eval = (tensor_eval - eval_mean) / (eval_std + 1e-8)\n",
    "        standardized_tensor_eval[~tensor_eval_bool] = np.nan  # Set unobserved points to NaN\n",
    "\n",
    "        # Create mask if needed\n",
    "        mask_tensor = None\n",
    "        if self.mask_ratio != 0:\n",
    "            mask_indices = self._select_mask_indices(\n",
    "                tensor_eval.shape, tensor_eval_bool\n",
    "            )\n",
    "            mask_tensor = self._create_mask_tensor(tensor_eval.shape, mask_indices)\n",
    "\n",
    "        init_tensor_eval = self.rng.normal(0, 1, tensor_eval.shape)\n",
    "\n",
    "        # Assign observed values\n",
    "        condition = np.logical_and(tensor_eval_bool, self._tensor_constraint)\n",
    "        init_tensor_eval[condition] = standardized_tensor_eval[condition]\n",
    "\n",
    "        # Incorporate constraint \n",
    "        if self._tensor_constraint is not None:\n",
    "\n",
    "            if maximize:\n",
    "                init_tensor_eval[self._tensor_constraint == 0] = np.nanmin(init_tensor_eval) - 1.0 * 1\n",
    "            else:\n",
    "                init_tensor_eval[self._tensor_constraint == 0] = np.nanmax(init_tensor_eval) + 1.0 * 1\n",
    "\n",
    "        # Perform CP decomposition\n",
    "        cp_tensor = parafac(\n",
    "            init_tensor_eval,\n",
    "            rank=self.cp_rank,\n",
    "            mask=mask_tensor,\n",
    "            n_iter_max=self.als_iter_num,\n",
    "            init=\"random\",\n",
    "            random_state=self.rng,  # Ensure the random state is passed\n",
    "        )\n",
    "        return cp_to_tensor(cp_tensor)\n",
    "\n",
    "    def _calculate_mean_std_tensors(\n",
    "        self,\n",
    "        tensors_list: list[np.ndarray],\n",
    "        tensor_eval: np.ndarray,\n",
    "        tensor_eval_bool: np.ndarray,\n",
    "        maximize: bool\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "        tensors_stack = np.stack(tensors_list)\n",
    "        mean_tensor = np.mean(tensors_stack, axis=0)\n",
    "        std_tensor = np.std(tensors_stack, axis=0)\n",
    "\n",
    "        mean_tensor[tensor_eval_bool] = tensor_eval[tensor_eval_bool]\n",
    "        std_tensor[tensor_eval_bool] = 0\n",
    "\n",
    "        if self._tensor_constraint is not None:\n",
    "            if maximize:\n",
    "                mean_tensor[self._tensor_constraint == 0] = np.min(mean_tensor) - 1.0\n",
    "            else:\n",
    "                mean_tensor[self._tensor_constraint == 0] = np.max(mean_tensor) + 1.0\n",
    "                \n",
    "            std_tensor[self._tensor_constraint == 0] = 0\n",
    "\n",
    "        # Debugging\n",
    "        self.mean_tensor = mean_tensor\n",
    "        self.std_tensor = std_tensor\n",
    "\n",
    "        return mean_tensor, std_tensor\n",
    "\n",
    "    def _suggest_ucb_candidates(\n",
    "        self,\n",
    "        mean_tensor: np.ndarray,\n",
    "        std_tensor: np.ndarray,\n",
    "        trade_off_param: float,\n",
    "        batch_size: int,\n",
    "        maximize: bool,\n",
    "    ) -> list[tuple[int, ...]]:\n",
    "        # # Calculate overall mean and std stats for logging\n",
    "        # mean_stats = {\n",
    "        #     \"Max\": np.max(mean_tensor),\n",
    "        #     \"Min\": np.min(mean_tensor),\n",
    "        #     \"Mean\": np.mean(mean_tensor),\n",
    "        #     \"Std\": np.std(mean_tensor),\n",
    "        # }\n",
    "        # std_stats = {\n",
    "        #     \"Max\": np.max(std_tensor),\n",
    "        #     \"Min\": np.min(std_tensor),\n",
    "        #     \"Mean\": np.mean(std_tensor),\n",
    "        #     \"Std\": np.std(std_tensor),\n",
    "        # }\n",
    "\n",
    "        # logging.info(f\"Candidate Mean Stats: {mean_stats}\")\n",
    "        # logging.info(f\"Candidate Std Stats: {std_stats}\")\n",
    "\n",
    "        # Define UCB calculation\n",
    "        def _ucb(mean_tensor, std_tensor, trade_off_param, maximize=True) -> np.ndarray:\n",
    "            mean_tensor = mean_tensor if maximize else -mean_tensor\n",
    "            ucb_values = mean_tensor + trade_off_param * std_tensor\n",
    "            return ucb_values\n",
    "\n",
    "        ucb_values = _ucb(mean_tensor, std_tensor, trade_off_param, maximize)\n",
    "\n",
    "        if self.unique_sampling:\n",
    "            ucb_values[self._tensor_eval_bool == True] = -np.inf\n",
    "\n",
    "        # Get indices of top UCB values\n",
    "        flat_indices = np.argsort(ucb_values.flatten())[::-1]\n",
    "        top_indices = np.unravel_index(flat_indices[:batch_size], ucb_values.shape)\n",
    "        top_indices = list(zip(*top_indices))\n",
    "\n",
    "        return top_indices\n",
    "\n",
    "    def _suggest_ei_candidates(\n",
    "        self,\n",
    "        mean_tensor: np.ndarray,\n",
    "        std_tensor: np.ndarray,\n",
    "        batch_size: int,\n",
    "        maximize: bool,\n",
    "    ) -> list[tuple[int, ...]]:\n",
    "        # # Calculate overall mean and std stats for logging\n",
    "        # mean_stats = {\n",
    "        #     \"Max\": np.max(mean_tensor),\n",
    "        #     \"Min\": np.min(mean_tensor),\n",
    "        #     \"Mean\": np.mean(mean_tensor),\n",
    "        #     \"Std\": np.std(mean_tensor),\n",
    "        # }\n",
    "        # std_stats = {\n",
    "        #     \"Max\": np.max(std_tensor),\n",
    "        #     \"Min\": np.min(std_tensor),\n",
    "        #     \"Mean\": np.mean(std_tensor),\n",
    "        #     \"Std\": np.std(std_tensor),\n",
    "        # }\n",
    "\n",
    "        # Define EI calculation\n",
    "        def _ei(mean_tensor, std_tensor, f_best, maximize=True) -> np.ndarray:\n",
    "            std_tensor = np.clip(std_tensor, 1e-9, None)\n",
    "            if maximize:\n",
    "                z = (mean_tensor - f_best) / std_tensor\n",
    "            else:\n",
    "                z = (f_best - mean_tensor) / std_tensor\n",
    "            ei_values = std_tensor * (z * norm.cdf(z) + norm.pdf(z))\n",
    "            return ei_values\n",
    "\n",
    "        if maximize:\n",
    "            f_best = np.nanmax(self._tensor_eval)\n",
    "        else:\n",
    "            f_best = np.nanmin(self._tensor_eval)\n",
    "\n",
    "        ei_values = _ei(mean_tensor, std_tensor, f_best=f_best, maximize=maximize)\n",
    "\n",
    "        if self.unique_sampling:\n",
    "            ei_values[self._tensor_eval_bool == True] = -np.inf\n",
    "\n",
    "        # Get indices of top EI values\n",
    "        flat_indices = np.argsort(ei_values.flatten())[::-1]\n",
    "        top_indices = np.unravel_index(flat_indices[:batch_size], ei_values.shape)\n",
    "        top_indices = list(zip(*top_indices))\n",
    "\n",
    "        return top_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 15:54:46,435] A new study created in memory with name: test_study\n",
      "[I 2024-12-07 15:54:46,436] Trial 0 finished with value: 10.0 and parameters: {'x_0_0': 'ab', 'x_0_1': 'cd', 'x_0_2': 'cd', 'x_1_0': 'oo', 'x_1_1': 'bc', 'x_1_2': 'bd'}. Best is trial 0 with value: 10.0.\n",
      "[I 2024-12-07 15:54:46,437] Trial 1 finished with value: 10.0 and parameters: {'x_0_0': 'bc', 'x_0_1': 'ac', 'x_0_2': 'ad', 'x_1_0': 'bd', 'x_1_1': 'cd', 'x_1_2': 'ad'}. Best is trial 0 with value: 10.0.\n",
      "[I 2024-12-07 15:54:46,438] Trial 2 finished with value: 0.9444444444444444 and parameters: {'x_0_0': 'ad', 'x_0_1': 'oo', 'x_0_2': 'cd', 'x_1_0': 'bc', 'x_1_1': 'oo', 'x_1_2': 'bd'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,439] Trial 3 finished with value: 10.0 and parameters: {'x_0_0': 'bd', 'x_0_1': 'bd', 'x_0_2': 'oo', 'x_1_0': 'bc', 'x_1_1': 'bc', 'x_1_2': 'ac'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,440] Trial 4 finished with value: 10.0 and parameters: {'x_0_0': 'ad', 'x_0_1': 'oo', 'x_0_2': 'ad', 'x_1_0': 'cd', 'x_1_1': 'bc', 'x_1_2': 'bd'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,440] Trial 5 finished with value: 10.0 and parameters: {'x_0_0': 'ab', 'x_0_1': 'oo', 'x_0_2': 'ab', 'x_1_0': 'ab', 'x_1_1': 'ad', 'x_1_2': 'cd'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,441] Trial 6 finished with value: 10.0 and parameters: {'x_0_0': 'ab', 'x_0_1': 'bd', 'x_0_2': 'oo', 'x_1_0': 'ab', 'x_1_1': 'ab', 'x_1_2': 'oo'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,442] Trial 7 finished with value: 10.0 and parameters: {'x_0_0': 'bc', 'x_0_1': 'oo', 'x_0_2': 'ac', 'x_1_0': 'bc', 'x_1_1': 'bd', 'x_1_2': 'bd'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,442] Trial 8 finished with value: 10.0 and parameters: {'x_0_0': 'bd', 'x_0_1': 'oo', 'x_0_2': 'cd', 'x_1_0': 'ac', 'x_1_1': 'ac', 'x_1_2': 'bd'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,443] Trial 9 finished with value: 10.0 and parameters: {'x_0_0': 'bc', 'x_0_1': 'cd', 'x_0_2': 'ad', 'x_1_0': 'ab', 'x_1_1': 'cd', 'x_1_2': 'ad'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,444] Trial 10 finished with value: 10.0 and parameters: {'x_0_0': 'bc', 'x_0_1': 'oo', 'x_0_2': 'ac', 'x_1_0': 'ad', 'x_1_1': 'bd', 'x_1_2': 'ab'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,445] Trial 11 finished with value: 10.0 and parameters: {'x_0_0': 'bc', 'x_0_1': 'bd', 'x_0_2': 'ab', 'x_1_0': 'oo', 'x_1_1': 'cd', 'x_1_2': 'ab'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,445] Trial 12 finished with value: 10.0 and parameters: {'x_0_0': 'ac', 'x_0_1': 'ad', 'x_0_2': 'ab', 'x_1_0': 'bd', 'x_1_1': 'oo', 'x_1_2': 'ac'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,446] Trial 13 finished with value: 10.0 and parameters: {'x_0_0': 'ac', 'x_0_1': 'bd', 'x_0_2': 'ac', 'x_1_0': 'oo', 'x_1_1': 'cd', 'x_1_2': 'bd'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,447] Trial 14 finished with value: 10.0 and parameters: {'x_0_0': 'ab', 'x_0_1': 'cd', 'x_0_2': 'ad', 'x_1_0': 'cd', 'x_1_1': 'bd', 'x_1_2': 'ab'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,448] Trial 15 finished with value: 10.0 and parameters: {'x_0_0': 'ac', 'x_0_1': 'bc', 'x_0_2': 'bc', 'x_1_0': 'ad', 'x_1_1': 'oo', 'x_1_2': 'ad'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,449] Trial 16 finished with value: 10.0 and parameters: {'x_0_0': 'ad', 'x_0_1': 'oo', 'x_0_2': 'cd', 'x_1_0': 'bc', 'x_1_1': 'cd', 'x_1_2': 'ac'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,450] Trial 17 finished with value: 10.0 and parameters: {'x_0_0': 'oo', 'x_0_1': 'oo', 'x_0_2': 'ab', 'x_1_0': 'bd', 'x_1_1': 'ab', 'x_1_2': 'ad'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,451] Trial 18 finished with value: 10.0 and parameters: {'x_0_0': 'bd', 'x_0_1': 'bd', 'x_0_2': 'oo', 'x_1_0': 'cd', 'x_1_1': 'ac', 'x_1_2': 'bc'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:46,451] Trial 19 finished with value: 10.0 and parameters: {'x_0_0': 'bd', 'x_0_1': 'oo', 'x_0_2': 'oo', 'x_1_0': 'oo', 'x_1_1': 'ad', 'x_1_2': 'ac'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:49,860] Trial 20 finished with value: 1.4 and parameters: {'x_0_0': 'cd', 'x_0_1': 'oo', 'x_0_2': 'bc', 'x_1_0': 'oo', 'x_1_1': 'ad', 'x_1_2': 'bc'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:53,291] Trial 21 finished with value: 1.3666666666666667 and parameters: {'x_0_0': 'bd', 'x_0_1': 'bc', 'x_0_2': 'ab', 'x_1_0': 'oo', 'x_1_1': 'oo', 'x_1_2': 'ad'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[I 2024-12-07 15:54:56,839] Trial 22 finished with value: 1.0666666666666667 and parameters: {'x_0_0': 'bc', 'x_0_1': 'oo', 'x_0_2': 'cd', 'x_1_0': 'oo', 'x_1_1': 'ac', 'x_1_2': 'ac'}. Best is trial 2 with value: 0.9444444444444444.\n",
      "[W 2024-12-07 15:54:57,679] Trial 23 failed with parameters: {} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/_b/b62kq0490fn2ptq7m4mbp8yr0000gp/T/ipykernel_13188/1338313694.py\", line 63, in objective\n",
      "    x[i, j] = trial.suggest_categorical(f\"x_{i}_{j}\", directions)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py\", line 402, in suggest_categorical\n",
      "    return self._suggest(name, CategoricalDistribution(choices=choices))\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py\", line 627, in _suggest\n",
      "    elif self._is_relative_param(name, distribution):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py\", line 659, in _is_relative_param\n",
      "    if name not in self.relative_params:\n",
      "                   ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py\", line 71, in relative_params\n",
      "    self._relative_params = self.study.sampler.sample_relative(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/_b/b62kq0490fn2ptq7m4mbp8yr0000gp/T/ipykernel_13188/1201016267.py\", line 94, in sample_relative\n",
      "    mean_tensor, std_tensor = self._fit(\n",
      "                              ^^^^^^^^^^\n",
      "  File \"/var/folders/_b/b62kq0490fn2ptq7m4mbp8yr0000gp/T/ipykernel_13188/1201016267.py\", line 204, in _fit\n",
      "    self._decompose_with_optional_mask(\n",
      "  File \"/var/folders/_b/b62kq0490fn2ptq7m4mbp8yr0000gp/T/ipykernel_13188/1201016267.py\", line 317, in _decompose_with_optional_mask\n",
      "    cp_tensor = parafac(\n",
      "                ^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/decomposition/_cp.py\", line 423, in parafac\n",
      "    mttkrp = unfolding_dot_khatri_rao(tensor, (weights, factors), mode)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/backend/__init__.py\", line 202, in wrapped_backend_method\n",
      "    return getattr(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/tenalg/core_tenalg/mttkrp.py\", line 48, in unfolding_dot_khatri_rao\n",
      "    kr_factors = khatri_rao(factors, weights=weights, skip_matrix=mode)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/tenalg/core_tenalg/_khatri_rao.py\", line 105, in khatri_rao\n",
      "    res = T.reshape(a * b, (-1, n_columns))\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/backend/__init__.py\", line 202, in wrapped_backend_method\n",
      "    return getattr(\n",
      "           ^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py\", line 328, in reshape\n",
      "    return _wrapfunc(a, 'reshape', shape, order=order)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/keisukeonoue/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py\", line 51, in _wrapfunc\n",
      "    def _wrapfunc(obj, method, *args, **kwds):\n",
      "    \n",
      "KeyboardInterrupt\n",
      "[W 2024-12-07 15:54:57,680] Trial 23 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 146\u001b[0m\n\u001b[1;32m    141\u001b[0m     optuna\u001b[38;5;241m.\u001b[39mvisualization\u001b[38;5;241m.\u001b[39mplot_optimization_history(study)\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m     \u001b[43mrun_bo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[39], line 134\u001b[0m, in \u001b[0;36mrun_bo\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m direction \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m settings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124macqf_settings\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    128\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(\n\u001b[1;32m    129\u001b[0m     study_name\u001b[38;5;241m=\u001b[39msettings[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    130\u001b[0m     sampler\u001b[38;5;241m=\u001b[39msampler,\n\u001b[1;32m    131\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[1;32m    132\u001b[0m )\n\u001b[0;32m--> 134\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_with_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miter_bo\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m best_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(map_shape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(map_shape[\u001b[38;5;241m0\u001b[39m]):\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[39], line 63\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial, map_shape, objective_function)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(map_shape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(map_shape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m---> 63\u001b[0m         x[i, j] \u001b[38;5;241m=\u001b[39m \u001b[43mtrial\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuggest_categorical\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mj\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdirections\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m objective_function(x)\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py:402\u001b[0m, in \u001b[0;36mTrial.suggest_categorical\u001b[0;34m(self, name, choices)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Suggest a value for the categorical parameter.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[38;5;124;03mThe value is sampled from ``choices``.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;124;03m    :ref:`configurations` tutorial describes more details and flexible usages.\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;66;03m# There is no need to call self._check_distribution because\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;66;03m# CategoricalDistribution does not support dynamic value space.\u001b[39;00m\n\u001b[0;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_suggest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCategoricalDistribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchoices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py:627\u001b[0m, in \u001b[0;36mTrial._suggest\u001b[0;34m(self, name, distribution)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m distribution\u001b[38;5;241m.\u001b[39msingle():\n\u001b[1;32m    626\u001b[0m     param_value \u001b[38;5;241m=\u001b[39m distributions\u001b[38;5;241m.\u001b[39m_get_single_value(distribution)\n\u001b[0;32m--> 627\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_relative_param\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistribution\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    628\u001b[0m     param_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_params[name]\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py:659\u001b[0m, in \u001b[0;36mTrial._is_relative_param\u001b[0;34m(self, name, distribution)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_relative_param\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, distribution: BaseDistribution) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_params\u001b[49m:\n\u001b[1;32m    660\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelative_search_space:\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/optuna/trial/_trial.py:71\u001b[0m, in \u001b[0;36mTrial.relative_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relative_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     study \u001b[38;5;241m=\u001b[39m pruners\u001b[38;5;241m.\u001b[39m_filter_study(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstudy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_frozen_trial)\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relative_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_relative\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cached_frozen_trial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelative_search_space\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_relative_params\n",
      "Cell \u001b[0;32mIn[37], line 94\u001b[0m, in \u001b[0;36mParafacSampler.sample_relative\u001b[0;34m(self, study, trial, search_space)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_tensor(study)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Perform CP decomposition and suggest next parameter set\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m mean_tensor, std_tensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_eval_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Suggest next indices based on the selected acquisition function\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39macquisition_function \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mucb\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Cell \u001b[0;32mIn[37], line 204\u001b[0m, in \u001b[0;36mParafacSampler._fit\u001b[0;34m(self, tensor_eval, tensor_eval_bool)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    196\u001b[0m     tensor_eval: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m    197\u001b[0m     tensor_eval_bool: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[1;32m    198\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[np\u001b[38;5;241m.\u001b[39mndarray, np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[1;32m    199\u001b[0m     eval_mean, eval_std \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_eval_stats(\n\u001b[1;32m    200\u001b[0m         tensor_eval\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    203\u001b[0m     tensors_list \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 204\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompose_with_optional_mask\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtensor_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtensor_eval_bool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m            \u001b[49m\u001b[43meval_std\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maximize\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    211\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecomp_iter_num)\n\u001b[1;32m    212\u001b[0m     ]\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_calculate_mean_std_tensors(\n\u001b[1;32m    215\u001b[0m         tensors_list, tensor_eval, tensor_eval_bool, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximize\n\u001b[1;32m    216\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[37], line 317\u001b[0m, in \u001b[0;36mParafacSampler._decompose_with_optional_mask\u001b[0;34m(self, tensor_eval, tensor_eval_bool, eval_mean, eval_std, maximize)\u001b[0m\n\u001b[1;32m    314\u001b[0m         init_tensor_eval[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tensor_constraint \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(init_tensor_eval) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# Perform CP decomposition\u001b[39;00m\n\u001b[0;32m--> 317\u001b[0m cp_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mparafac\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_tensor_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcp_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_iter_max\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mals_iter_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Ensure the random state is passed\u001b[39;49;00m\n\u001b[1;32m    324\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cp_to_tensor(cp_tensor)\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/decomposition/_cp.py:423\u001b[0m, in \u001b[0;36mparafac\u001b[0;34m(tensor, rank, n_iter_max, init, svd, normalize_factors, orthogonalise, tol, random_state, verbose, return_errors, sparsity, l2_reg, mask, cvg_criterion, fixed_modes, svd_mask_repeats, linesearch, callback)\u001b[0m\n\u001b[1;32m    417\u001b[0m pseudo_inverse \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m Id\n\u001b[1;32m    418\u001b[0m pseudo_inverse \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    419\u001b[0m     tl\u001b[38;5;241m.\u001b[39mreshape(weights, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;241m*\u001b[39m pseudo_inverse\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;241m*\u001b[39m tl\u001b[38;5;241m.\u001b[39mreshape(weights, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    422\u001b[0m )\n\u001b[0;32m--> 423\u001b[0m mttkrp \u001b[38;5;241m=\u001b[39m \u001b[43munfolding_dot_khatri_rao\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    425\u001b[0m factor \u001b[38;5;241m=\u001b[39m tl\u001b[38;5;241m.\u001b[39mtranspose(\n\u001b[1;32m    426\u001b[0m     tl\u001b[38;5;241m.\u001b[39msolve(tl\u001b[38;5;241m.\u001b[39mconj(tl\u001b[38;5;241m.\u001b[39mtranspose(pseudo_inverse)), tl\u001b[38;5;241m.\u001b[39mtranspose(mttkrp))\n\u001b[1;32m    427\u001b[0m )\n\u001b[1;32m    428\u001b[0m factors[mode] \u001b[38;5;241m=\u001b[39m factor\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/backend/__init__.py:202\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A dynamically dispatched method\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Returns the queried method from the currently set backend\"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/tenalg/core_tenalg/mttkrp.py:48\u001b[0m, in \u001b[0;36munfolding_dot_khatri_rao\u001b[0;34m(tensor, cp_tensor, mode)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"mode-n unfolding times khatri-rao product of factors\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     47\u001b[0m weights, factors \u001b[38;5;241m=\u001b[39m cp_tensor\n\u001b[0;32m---> 48\u001b[0m kr_factors \u001b[38;5;241m=\u001b[39m \u001b[43mkhatri_rao\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfactors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_matrix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m mttkrp \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mdot(unfold(tensor, mode), T\u001b[38;5;241m.\u001b[39mconj(kr_factors))\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mttkrp\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/tenalg/core_tenalg/_khatri_rao.py:105\u001b[0m, in \u001b[0;36mkhatri_rao\u001b[0;34m(matrices, weights, skip_matrix, mask)\u001b[0m\n\u001b[1;32m    103\u001b[0m     a \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mreshape(res, (s1, \u001b[38;5;241m1\u001b[39m, s2))\n\u001b[1;32m    104\u001b[0m     b \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mreshape(e, (\u001b[38;5;241m1\u001b[39m, s3, s4))\n\u001b[0;32m--> 105\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_columns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m m \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mreshape(mask, (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res \u001b[38;5;241m*\u001b[39m m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/tensorly/backend/__init__.py:202\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A dynamically dispatched method\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Returns the queried method from the currently set backend\"\"\"\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:328\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, shape, order, newshape, copy)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreshape\u001b[39m\u001b[38;5;124m'\u001b[39m, shape, order\u001b[38;5;241m=\u001b[39morder, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreshape\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/ws/constrained_BO_v3/bo-env_v3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:51\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     46\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m conv\u001b[38;5;241m.\u001b[39mwrap(result, to_scalar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapfunc\u001b[39m(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     52\u001b[0m     bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import optuna\n",
    "from functools import partial\n",
    "from _src import WarcraftObjective\n",
    "\n",
    "\n",
    "def build_constraint_warcraft(map_shape: tuple[int, int]) -> np.ndarray:\n",
    "    # Directions dictionary\n",
    "    directions_dict = {\n",
    "        \"oo\": np.array([0, 0]),\n",
    "        \"ab\": np.array([1, 1]),\n",
    "        \"ac\": np.array([0, 2]),\n",
    "        \"ad\": np.array([1, 1]),\n",
    "        \"bc\": np.array([1, 1]),\n",
    "        \"bd\": np.array([2, 0]),\n",
    "        \"cd\": np.array([1, 1]),\n",
    "    }\n",
    "\n",
    "    directions_list = list(directions_dict.keys())\n",
    "\n",
    "    # Map parameters\n",
    "    map_length = map_shape[0] * map_shape[1]\n",
    "    ideal_gain = (map_shape[0] + map_shape[1] - 1) * 2\n",
    "\n",
    "    # Initialize constraints as NumPy arrays\n",
    "    tensor_constraint_1 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_2 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_3 = np.zeros((len(directions_list),) * map_length)\n",
    "\n",
    "    # Constraint 1: (0, 0) != \"oo\", \"ab\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"ab\"]:\n",
    "            # tensor_constraint_1[..., directions_list.index(direction)] = 1\n",
    "            tensor_constraint_1[directions_list.index(direction), ...] = 1\n",
    "\n",
    "    # Constraint 2: (map_shape[0] - 1, map_shape[1] - 1) != \"oo\", \"cd\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"cd\"]:\n",
    "            # tensor_constraint_2[directions_list.index(direction), ...] = 1\n",
    "            tensor_constraint_2[..., directions_list.index(direction)] = 1\n",
    "\n",
    "    # Constraint 3: len[path] == map_shape[0] * map_shape[1]\n",
    "    for index, _ in np.ndenumerate(tensor_constraint_3):\n",
    "        gain = np.sum([directions_dict[directions_list[idx]].sum() for idx in index])\n",
    "        if gain == ideal_gain:\n",
    "            tensor_constraint_3[index] = 1\n",
    "\n",
    "    # Combine constraints with logical AND\n",
    "    tensor_constraint = np.logical_and(\n",
    "        tensor_constraint_1,\n",
    "        np.logical_and(tensor_constraint_2, tensor_constraint_3)\n",
    "    )\n",
    "\n",
    "    return tensor_constraint\n",
    "\n",
    "\n",
    "def objective(trial, map_shape=None, objective_function=None):\n",
    "    directions = [\"oo\", \"ab\", \"ac\", \"ad\", \"bc\", \"bd\", \"cd\"]\n",
    "    x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            x[i, j] = trial.suggest_categorical(f\"x_{i}_{j}\", directions)\n",
    "    return objective_function(x)\n",
    "\n",
    "\n",
    "def get_map(map_option: int):\n",
    "    if map_option == 1:\n",
    "        map_targeted = np.array([[1, 4], [2, 1]])\n",
    "    elif map_option == 2:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 1]])\n",
    "    elif map_option == 3:\n",
    "        map_targeted = np.array([[1, 4, 1], [2, 1, 3], [5, 2, 1]])\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid map option: {map_option}\")\n",
    "    return map_targeted / map_targeted.sum()\n",
    "\n",
    "\n",
    "def run_bo():\n",
    "    settings = {\n",
    "        \"name\": \"test_study\",\n",
    "        \"seed\": 1,\n",
    "        \"map_option\": 2,\n",
    "        \"iter_bo\": 100,\n",
    "        \"unique_sampling\": False,\n",
    "        \"decomp_num\": 10,\n",
    "        \"cp_settings\": {\n",
    "            \"rank\": 3,\n",
    "            \"als_iterations\": 100,\n",
    "            \"mask_ratio\": 0.9,\n",
    "            \"include_observed_points\": False,\n",
    "        },\n",
    "        \"acqf_settings\": {\n",
    "            \"acquisition_function\": \"ei\",\n",
    "            \"trade_off_param\": 3.0,\n",
    "            \"batch_size\": 1,\n",
    "            \"maximize\": False,\n",
    "        },\n",
    "        \"n_startup_trials\": 20,\n",
    "    }\n",
    "\n",
    "    random.seed(settings['seed'])\n",
    "\n",
    "    map_targeted = get_map(settings[\"map_option\"])\n",
    "    map_shape = map_targeted.shape\n",
    "\n",
    "    tensor_constraint = build_constraint_warcraft(map_shape)\n",
    "\n",
    "    objective_function = WarcraftObjective(map_targeted, tensor_constraint=tensor_constraint)\n",
    "    objective_with_args = partial(objective, map_shape=map_shape, objective_function=objective_function)\n",
    "\n",
    "    sampler = ParafacSampler(\n",
    "        cp_rank=settings[\"cp_settings\"][\"rank\"],\n",
    "        als_iter_num=settings[\"cp_settings\"][\"als_iterations\"],\n",
    "        mask_ratio=settings[\"cp_settings\"][\"mask_ratio\"],\n",
    "        acquisition_function=settings[\"acqf_settings\"][\"acquisition_function\"],\n",
    "        trade_off_param=settings[\"acqf_settings\"][\"trade_off_param\"],\n",
    "        seed=settings[\"seed\"],\n",
    "        unique_sampling=settings[\"unique_sampling\"],\n",
    "        decomp_iter_num=settings[\"decomp_num\"],\n",
    "        n_startup_trials=settings[\"n_startup_trials\"],\n",
    "        include_observed_points=settings[\"cp_settings\"].get(\"include_observed_points\", False),\n",
    "        tensor_constraint=tensor_constraint,\n",
    "    )\n",
    "\n",
    "    direction = \"maximize\" if settings[\"acqf_settings\"][\"maximize\"] else \"minimize\"\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=settings[\"name\"],\n",
    "        sampler=sampler,\n",
    "        direction=direction,\n",
    "    )\n",
    "\n",
    "    study.optimize(objective_with_args, n_trials=settings[\"iter_bo\"])\n",
    "\n",
    "    best_x = np.empty(map_shape, dtype=object)\n",
    "    for i in range(map_shape[0]):\n",
    "        for j in range(map_shape[1]):\n",
    "            best_x[i, j] = study.best_params[f\"x_{i}_{j}\"]\n",
    "\n",
    "    optuna.visualization.plot_optimization_history(study)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_bo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 7, 7, 7)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2401"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7**4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(300)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [0, 1],\n",
       "        [1, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.random.randint(0, 2, (4, 3, 2))\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(0), np.int64(1), np.int64(1))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[(0, 0, 0)], arr[(-1, -1, -1)], arr[(0, -1, -1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0, 1],\n",
       "        [0, 1],\n",
       "        [1, 2]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 0],\n",
       "        [1, 0]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1],\n",
       "        [0, 1]],\n",
       "\n",
       "       [[0, 0],\n",
       "        [1, 1],\n",
       "        [1, 1]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[(0, -1, -1)] = 2\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array([\n",
    "    [\"aa\", \"ab\", \"ac\"],\n",
    "    [\"ba\", \"bb\", \"bc\"],\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['aa' 'ab' 'ac' 'ad']\n",
      " ['ba' 'bb' 'bc' 'bd']\n",
      " ['ca' 'cb' 'cc' 'cd']\n",
      " ['da' 'db' 'dc' 'dd']]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 元のリスト\n",
    "elements = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "# 2文字の組み合わせを作成し、2次元配列に整形\n",
    "arr = np.array([[f\"{x}{y}\" for y in elements] for x in elements])\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'ab', 'ac', 'ad'], dtype='<U2')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['aaa' 'aab' 'aac' 'aad']\n",
      "  ['aba' 'abb' 'abc' 'abd']\n",
      "  ['aca' 'acb' 'acc' 'acd']\n",
      "  ['ada' 'adb' 'adc' 'add']]\n",
      "\n",
      " [['baa' 'bab' 'bac' 'bad']\n",
      "  ['bba' 'bbb' 'bbc' 'bbd']\n",
      "  ['bca' 'bcb' 'bcc' 'bcd']\n",
      "  ['bda' 'bdb' 'bdc' 'bdd']]\n",
      "\n",
      " [['caa' 'cab' 'cac' 'cad']\n",
      "  ['cba' 'cbb' 'cbc' 'cbd']\n",
      "  ['cca' 'ccb' 'ccc' 'ccd']\n",
      "  ['cda' 'cdb' 'cdc' 'cdd']]\n",
      "\n",
      " [['daa' 'dab' 'dac' 'dad']\n",
      "  ['dba' 'dbb' 'dbc' 'dbd']\n",
      "  ['dca' 'dcb' 'dcc' 'dcd']\n",
      "  ['dda' 'ddb' 'ddc' 'ddd']]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 元のリスト\n",
    "elements = [\"a\", \"b\", \"c\", \"d\"]\n",
    "\n",
    "# 3つの要素の組み合わせを3階テンソルとして生成\n",
    "tensor = np.array([[[f\"{x}{y}{z}\" for z in elements] \n",
    "                     for y in elements] \n",
    "                     for x in elements])\n",
    "\n",
    "print(tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['aaa', 'aba', 'aca', 'ada'],\n",
       "       ['baa', 'bba', 'bca', 'bda'],\n",
       "       ['caa', 'cba', 'cca', 'cda'],\n",
       "       ['daa', 'dba', 'dca', 'dda']], dtype='<U3')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[(..., 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['aaa', 'aab', 'aac', 'aad'],\n",
       "       ['aba', 'abb', 'abc', 'abd'],\n",
       "       ['aca', 'acb', 'acc', 'acd'],\n",
       "       ['ada', 'adb', 'adc', 'add']], dtype='<U3')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[0, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_constraint_warcraft(map_shape: tuple[int, int]) -> np.ndarray:\n",
    "    # Directions dictionary\n",
    "    directions_dict = {\n",
    "        \"oo\": np.array([0, 0]),\n",
    "        \"ab\": np.array([1, 1]),\n",
    "        \"ac\": np.array([0, 2]),\n",
    "        \"ad\": np.array([1, 1]),\n",
    "        \"bc\": np.array([1, 1]),\n",
    "        \"bd\": np.array([2, 0]),\n",
    "        \"cd\": np.array([1, 1]),\n",
    "    }\n",
    "\n",
    "    directions_list = list(directions_dict.keys())\n",
    "\n",
    "    # Map parameters\n",
    "    map_length = map_shape[0] * map_shape[1]\n",
    "    ideal_gain = (map_shape[0] + map_shape[1] - 1) * 2\n",
    "\n",
    "    # Initialize constraints as NumPy arrays\n",
    "    tensor_constraint_1 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_2 = np.zeros((len(directions_list),) * map_length)\n",
    "    tensor_constraint_3 = np.zeros((len(directions_list),) * map_length)\n",
    "\n",
    "    # Constraint 1: (0, 0) != \"oo\", \"ab\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"ab\"]:\n",
    "            tensor_constraint_1[directions_list.index(direction), ...] = 1\n",
    "\n",
    "    # Constraint 2: (map_shape[0] - 1, map_shape[1] - 1) != \"oo\", \"cd\"\n",
    "    for direction in directions_list:\n",
    "        if direction not in [\"oo\", \"cd\"]:\n",
    "            tensor_constraint_2[..., directions_list.index(direction)] = 1\n",
    "\n",
    "    # Constraint 3: len[path] == map_shape[0] * map_shape[1]\n",
    "    for index, _ in np.ndenumerate(tensor_constraint_3):\n",
    "        gain = np.sum([directions_dict[directions_list[idx]].sum() for idx in index])\n",
    "        if gain == ideal_gain:\n",
    "            tensor_constraint_3[index] = 1\n",
    "\n",
    "    # Combine constraints with logical AND\n",
    "    tensor_constraint = np.logical_and(\n",
    "        tensor_constraint_1,\n",
    "        np.logical_and(tensor_constraint_2, tensor_constraint_3)\n",
    "    )\n",
    "\n",
    "    return tensor_constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = build_constraint_warcraft((1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True,  True,  True],\n",
       "       [ True, False, False, False, False, False,  True],\n",
       "       [ True, False, False, False, False, False,  True],\n",
       "       [ True, False, False, False, False, False,  True],\n",
       "       [ True, False, False, False, False, False,  True],\n",
       "       [ True, False, False, False, False, False,  True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "~tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bo-env_v3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
